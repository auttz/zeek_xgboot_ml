import os, sys, glob, time, datetime, shutil, ipaddress
import pandas as pd
import joblib
from minio import Minio
from sklearn.metrics import classification_report, accuracy_score
from jinja2 import Environment, FileSystemLoader
from prepare_data import transform_data

# ------------------------------
# üåç Global Path Settings
# ------------------------------
BASE_OUTPUT_DIR = os.getenv("OUTPUT_DIR", "data/output")
os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)


# -------------------------------------------
# 1Ô∏è‚É£ Helper: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ CSV ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
# -------------------------------------------
def get_latest_csv(input_folder):
    csv_files = glob.glob(os.path.join(input_folder, "*.csv")) + glob.glob(os.path.join(input_folder, "*.CSV"))
    if not csv_files:
        sys.exit(f"‚ùå No CSV files found in input folder: {input_folder}")
    latest = max(csv_files, key=os.path.getmtime)
    print(f"üïí Latest CSV selected: {os.path.basename(latest)}")
    return latest


# -------------------------------------------
# 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• + ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
# -------------------------------------------
def load_and_prepare_data(latest_csv):
    print(f"üì• Loading: {latest_csv}")
    df = pd.read_csv(latest_csv, on_bad_lines='skip')
    print(f"üî¢ Total rows: {len(df)}")
    print("üßπ Transforming features ...")
    df_clean = transform_data(df)
    return df, df_clean


# -------------------------------------------
# 3Ô∏è‚É£ ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
# -------------------------------------------
def run_prediction(model_path, df, df_clean):
    print("ü§ñ Loading trained model ...")
    model = joblib.load(model_path)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ label ‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏° (‡∏Å‡∏£‡∏ì‡∏µ training/test)
    if "label" in df_clean.columns:
        x_data = df_clean.drop(columns=["label"])
        y_true = df_clean["label"]
        labeled = True
    else:
        x_data = df_clean
        y_true = None
        labeled = False
        print("‚ö†Ô∏è No 'label' column found ‚Äî running in unlabeled mode.")

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå
    print("üîÆ Predicting ...")
    start = time.time()
    y_pred = model.predict(x_data)
    duration = time.time() - start

    df_result = df.copy()
    df_result["prediction"] = y_pred

    # -------------------------------------------
    # ‚úÖ Whitelist Filtering: Microsoft / Windows / Mozilla Internal Traffic
    # -------------------------------------------
    def is_internal_ip(ip):
        try:
            return ipaddress.ip_address(ip).is_private
        except:
            return False

    def is_whitelisted(row):
        ua = str(row.get("user_agent.original", "")).lower()
        src_ip = str(row.get("source.ip", ""))
        dest_ip = str(row.get("destination.ip", ""))
        status = str(row.get("http.response.status_code", ""))

        # Rule 1: Microsoft / Windows System Traffic
        ms_keywords = [
            "msftconnecttest", "microsoft", "windows update", "cryptoapi",
            "windowsupdate", "officecdn", "outlook", "onenote",
            "onedrive", "bingbot", "defender"
        ]
        if any(k in ua for k in ms_keywords):
            # ‚úÖ ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Å‡∏ß‡πà‡∏≤: ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô private src_ip ‡∏´‡∏£‡∏∑‡∏≠ status ‡∏õ‡∏Å‡∏ï‡∏¥
            if ipaddress.ip_address(src_ip).is_private or status.startswith("20"):
                return True

        # Rule 2: Apple / Mozilla Internal Traffic (‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà benign)
        if any(k in ua for k in ["applewebkit", "mozilla", "safari", "iphone", "ipad"]):
            if ipaddress.ip_address(src_ip).is_private:
                return True

        # Rule 3: Known Safe Domains
        safe_domains = ["microsoft.com", "windows.com", "update.microsoft", "office.com"]
        url = str(row.get("url.original", "")).lower()
        if any(domain in url for domain in safe_domains):
            return True

        return False


    df_result["is_whitelist"] = df_result.apply(is_whitelisted, axis=1)
    whitelist_count = df_result["is_whitelist"].sum()

    if whitelist_count > 0:
        print(f"üß© Found {whitelist_count} whitelisted benign logs (internal Microsoft/Mozilla).")

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å whitelist logs ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ß‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
        whitelist_path = os.path.join(BASE_OUTPUT_DIR, "whitelist_filtered.csv")
        df_result[df_result["is_whitelist"] == True].to_csv(whitelist_path, index=False)
        print(f"üíæ Whitelist entries saved ‚Üí {whitelist_path}")

        # ‚öôÔ∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô prediction ‡∏Ç‡∏≠‡∏á whitelist ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 0 (‡∏õ‡∏Å‡∏ï‡∏¥)
        df_result.loc[df_result["is_whitelist"] == True, "prediction"] = 0

    # üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡πÄ‡∏Å‡πá‡∏ö‡∏ó‡∏∏‡∏Å log ‡∏ó‡∏±‡πâ‡∏á normal + alert)
    output_csv_path = os.path.join(BASE_OUTPUT_DIR, "predict_result.csv")
    df_result.to_csv(output_csv_path, index=False)
    print(f"üíæ Saved predictions ‚Üí {output_csv_path}")

    # üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    total_logs = len(df_result)
    alerts = int((df_result["prediction"] == 1).sum())
    normals = total_logs - alerts
    print(f"üìä Summary: Total={total_logs} | Whitelist={whitelist_count} | Alerts(after filter)={alerts} | Normal={normals}")

    # üìà ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Accuracy (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ label)
    acc, report_html = None, "<p>No ground truth labels available.</p>"
    if labeled:
        acc = accuracy_score(y_true, y_pred)
        print(f"‚úÖ Accuracy: {acc*100:.2f}%")
        report_dict = classification_report(y_true, y_pred, output_dict=True)
        for lbl, metrics in report_dict.items():
            if isinstance(metrics, dict):
                for k, v in metrics.items():
                    metrics[k] = round(v * 100, 2) if k != "support" else int(v)
        df_report = pd.DataFrame(report_dict).transpose()
        report_html = df_report.to_html(classes="table table-striped table-bordered", border=0)

    return y_pred, acc, report_html, duration


# 4Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á HTML Report
def generate_html_report(acc, duration, report_html):
    env = Environment(loader=FileSystemLoader("templates"))
    template = env.get_template("report_predict_template.html")
    context = {
        "accuracy": f"{acc*100:.2f}%" if acc else "N/A",
        "duration": f"{duration:.2f}",
        "params": {},
        "report_html": report_html,
    }
    output_html_path = os.path.join(BASE_OUTPUT_DIR, "classification_report_predict.html")
    html_out = template.render(context)
    with open(output_html_path, "w", encoding="utf-8") as f:
        f.write(html_out)
    print(f"üìë HTML report saved ‚Üí {output_html_path}")
    return output_html_path


# 5Ô∏è‚É£ Upload ‡∏Ç‡∏∂‡πâ‡∏ô MinIO
def upload_to_minio():
    try:
        client = Minio(
            os.getenv("MINIO_ENDPOINT", "localhost:9000"),
            access_key=os.getenv("MINIO_ACCESS_KEY", "admin"),
            secret_key=os.getenv("MINIO_SECRET_KEY", "12345678"),
            secure=False
        )

        bucket_name = "zeek-data"
        if not client.bucket_exists(bucket_name):
            client.make_bucket(bucket_name)
            print(f"‚úÖ Created bucket: {bucket_name}")

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        print("\nüì§ Uploading to MinIO:")

        # üßæ HTML Report
        report_path = os.path.join(BASE_OUTPUT_DIR, "classification_report_predict.html")
        if os.path.exists(report_path):
            obj_path = f"reports/{timestamp}/classification_report_predict.html"
            print(f"‚Üí {obj_path}")
            client.fput_object(bucket_name, obj_path, report_path)

        # üìä CSV
        csv_path = os.path.join(BASE_OUTPUT_DIR, "predict_result.csv")
        if os.path.exists(csv_path):
            obj_path = f"datasets/{timestamp}/predict_result.csv"
            print(f"‚Üí {obj_path}")
            client.fput_object(bucket_name, obj_path, csv_path)

        # üß† Model
        model_path = os.path.join(BASE_OUTPUT_DIR, "xgboost-model.pkl")
        if os.path.exists(model_path):
            obj_path = f"models/{timestamp}/xgboost-model.pkl"
            print(f"‚Üí {obj_path}")
            client.fput_object(bucket_name, obj_path, model_path)

        # üóíÔ∏è Log
        log_path = os.path.join(BASE_OUTPUT_DIR, "archive_log.txt")
        if os.path.exists(log_path):
            obj_path = f"logs/{timestamp}/archive_log.txt"
            print(f"‚Üí {obj_path}")
            client.fput_object(bucket_name, obj_path, log_path)

        print("‚úÖ Upload complete!\n")

    except Exception as e:
        print(f"‚ùå Upload failed: {e}")


# 6Ô∏è‚É£ ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ archive ‡πÅ‡∏•‡∏∞ log
def archive_and_log(latest_csv, input_folder, acc, duration, df_len):
    archive_dir = os.path.join(input_folder, "archive")
    os.makedirs(archive_dir, exist_ok=True)
    shutil.move(latest_csv, os.path.join(archive_dir, os.path.basename(latest_csv)))

    log_file = os.path.join(BASE_OUTPUT_DIR, "archive_log.txt")
    with open(log_file, "a", encoding="utf-8") as log:
        log.write(
            f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] "
            f"Predicted: {os.path.basename(latest_csv)}, "
            f"Accuracy: {f'{acc*100:.2f}%' if acc else 'N/A'}, "
            f"Rows: {df_len}, "
            f"Duration: {duration:.2f} sec\n"
        )
    print("üóÉ Archived input file & updated log.")


# 7Ô∏è‚É£ MAIN PIPELINE
def main():
    if len(sys.argv) < 4:
        sys.exit("Usage: python predict.py <model_path> <input_folder> <output_html>")

    model_path, input_folder, _ = sys.argv[1:4]
    model_path = os.path.abspath(model_path)
    input_folder = os.path.abspath(input_folder)

    print(f"üß≠ Model path: {model_path}")
    print(f"üìÇ Input folder: {input_folder}")

    latest_csv = get_latest_csv(input_folder)
    df, df_clean = load_and_prepare_data(latest_csv)
    y_pred, acc, report_html, duration = run_prediction(model_path, df, df_clean)

    html_output_path = generate_html_report(acc, duration, report_html)
    upload_to_minio()
    archive_and_log(latest_csv, input_folder, acc, duration, len(df))
    print(f"‚úÖ Finished successfully in {duration:.2f} seconds.")


if __name__ == "__main__":
    main()
