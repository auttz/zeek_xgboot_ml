import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import re
import os

# ----------------------------
# ğŸ§­ Page Config
# ----------------------------
st.set_page_config(
    page_title="Zeek XGBoost ML Dashboard",
    page_icon="ğŸ§ ",
    layout="wide"
)

st.title("ğŸ§  Zeek XGBoost ML Dashboard v3")
st.markdown("Monitoring and Insights Dashboard for Zeek ML Pipeline")

# ----------------------------
# ğŸ“¥ Load Data
# ----------------------------
PREDICT_FILE = "data/output/predict_result.csv"
ARCHIVE_FILE = "data/output/archive_log.txt"

if not os.path.exists(PREDICT_FILE):
    st.warning("âš ï¸ predict_result.csv not found. Please run the prediction pipeline first.")
    st.stop()

# Load prediction result
df = pd.read_csv(PREDICT_FILE, on_bad_lines='skip')

# Clean column names (if needed)
df.columns = df.columns.str.strip()

# Check for prediction column
if 'prediction' not in df.columns:
    st.error("âŒ 'prediction' column not found in predict_result.csv")
    st.stop()

# ----------------------------
# ğŸ§© Model Summary
# ----------------------------
st.subheader("ğŸ“Š Model Summary")
total_logs = len(df)
alerts = int(df['prediction'].sum())
normals = total_logs - alerts
alert_ratio = (alerts / total_logs * 100) if total_logs > 0 else 0

col1, col2, col3 = st.columns(3)
col1.metric("ğŸ§¾ Total Logs", f"{total_logs:,}")
col2.metric("ğŸš¨ Alerts", f"{alerts:,} ({alert_ratio:.1f}%)")
col3.metric("âœ… Normal", f"{normals:,}")

# ----------------------------
# ğŸ“ˆ Bar Chart (Alerts vs Normal)
# ----------------------------
st.markdown("### ğŸ“Š Alert Distribution")

# à¹ƒà¸Šà¹‰ columns à¸Šà¹ˆà¸§à¸¢à¸ˆà¸±à¸”à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¸à¸¶à¹ˆà¸‡à¸à¸¥à¸²à¸‡à¹à¸¥à¸°à¸„à¸§à¸šà¸„à¸¸à¸¡à¸‚à¸™à¸²à¸”
col1, col2, col3 = st.columns([1, 2, 1])  # col2 à¸„à¸·à¸­à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸«à¸¥à¸±à¸à¸‚à¸­à¸‡à¸à¸£à¸²à¸Ÿ
with col2:
    fig, ax = plt.subplots(figsize=(2, 1.2))  # ğŸ‘ˆ à¸à¸³à¸«à¸™à¸”à¸‚à¸™à¸²à¸”à¹€à¸¥à¹‡à¸
    ax.bar(["Normal", "Alert"], [normals, alerts],
           color=["#4CAF50", "#FF5252"], width=0.5)
    ax.set_ylabel("Count", fontsize=8)
    ax.tick_params(axis="both", labelsize=8)
    ax.set_xlabel("")  # à¹„à¸¡à¹ˆà¹ƒà¸«à¹‰à¸Šà¸·à¹ˆà¸­à¹à¸à¸™à¸¥à¹ˆà¸²à¸‡à¸à¸´à¸™à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆ
    for spine in ax.spines.values():
        spine.set_visible(False)
    st.pyplot(fig, use_container_width=False)

# ----------------------------
# ğŸ•’ Pipeline Run Summary
# ----------------------------
if os.path.exists(ARCHIVE_FILE):
    st.subheader("ğŸ•’ Pipeline Run Summary")

    with open(ARCHIVE_FILE, "r", encoding="utf-8") as f:
        lines = f.read().splitlines()
    log_df = pd.DataFrame(lines, columns=["raw"])

    # Extract data with regex
    log_df["Timestamp"] = log_df["raw"].str.extract(r"\[(.*?)\]")
    log_df["File"] = log_df["raw"].str.extract(r"Predicted:\s*(.*?),")
    log_df["Accuracy"] = log_df["raw"].str.extract(r"Accuracy:\s*([\d.]+)%").astype(float)
    log_df["Rows"] = log_df["raw"].str.extract(r"Rows:\s*(\d+)").astype(float)
    log_df["Duration"] = log_df["raw"].str.extract(r"Duration:\s*([\d.]+)").astype(float)

    # Show average stats
    if not log_df["Accuracy"].isna().all():
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ“Š Avg Accuracy", f"{log_df['Accuracy'].mean():.2f}%")
        c2.metric("ğŸ§¾ Avg Rows per Run", f"{log_df['Rows'].mean():,.0f}")
        c3.metric("âš¡ Avg Duration", f"{log_df['Duration'].mean():.2f} sec")

    # Show last 5 runs
    st.write("ğŸ“œ **Recent Runs**")
    st.dataframe(log_df[["Timestamp", "File", "Accuracy", "Rows", "Duration"]].tail(5), use_container_width=True)

else:
    st.info("â„¹ï¸ No archive_log.txt found yet â€” run prediction at least once.")

# ----------------------------
# ğŸ§® Recent Predictions
# ----------------------------
st.subheader("ğŸ§© Recent Predictions")

# à¹à¸ªà¸”à¸‡à¹€à¸‰à¸à¸²à¸°à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸ªà¸³à¸„à¸±à¸à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢
cols_to_show = [c for c in df.columns if c in ["@timestamp", "destination.port", "network.protocol", "user_agent.original", "http.request.method", "prediction"]]
if len(cols_to_show) > 0:
    st.dataframe(df[cols_to_show].tail(10), use_container_width=True)
else:
    st.dataframe(df.tail(10), use_container_width=True)

# ----------------------------
# ğŸ•“ Archive Log (Raw)
# ----------------------------
st.subheader("ğŸ—‚ï¸ Archive Log (Latest 10 Records)")
if os.path.exists(ARCHIVE_FILE):
    archive_lines = open(ARCHIVE_FILE, "r", encoding="utf-8").read().splitlines()
    if archive_lines:
        recent_logs = archive_lines[-10:]
        log_df = pd.DataFrame({
            "Timestamp": [re.search(r"\[(.*?)\]", x).group(1) if re.search(r"\[(.*?)\]", x) else None for x in recent_logs],
            "Event": [x for x in recent_logs]
        })
        st.dataframe(log_df, use_container_width=True)
    else:
        st.write("No logs recorded yet.")
else:
    st.write("No archive_log.txt found.")

# ----------------------------
# ğŸ”„ Refresh Button
# ----------------------------
if st.button("ğŸ”„ Refresh Data"):
    st.cache_data.clear()
    st.rerun()

# ----------------------------
# ğŸ•’ Last Update Time
# ----------------------------
st.caption(f"ğŸ•’ Last refreshed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
